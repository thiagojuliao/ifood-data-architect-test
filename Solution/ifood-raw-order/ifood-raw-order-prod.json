{"paragraphs":[{"title":"Inicialização dos pacotes, definindo funções e variáveis","text":"%pyspark\n\n###############################################\n#   Importando pacotes & definindo funções    #\n###############################################\n\nfrom datetime import *\nfrom pyspark import StorageLevel\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\n\n###############################\n#   Definição de variáveis    #\n###############################\n\n# Definição do Schema de garnishItems que é um Array dentro de Items\nschema_value_currency = StructType([StructField(\"value\", StringType()), StructField(\"currency\", StringType())])\nschema_garnish = StructType(\n    [\n        StructField(\"name\", StringType()),\n        StructField(\"addition\", schema_value_currency),\n        StructField(\"discount\", schema_value_currency),\n        StructField(\"quantity\", DoubleType()),\n        StructField(\"sequence\", IntegerType()),\n        StructField(\"unitPrice\", schema_value_currency),\n        StructField(\"categoryId\", StringType()),\n        StructField(\"externalId\", StringType()),\n        StructField(\"totalValue\", schema_value_currency),\n        StructField(\"categoryName\", StringType()),\n        StructField(\"integrationId\", StringType())\n    ])\n\n# Definição do Schema do Array de Items\nschema_items = StructType(\n    [\n        StructField(\"name\", StringType()),\n        StructField(\"addition\", schema_value_currency),\n        StructField(\"discount\", schema_value_currency),\n        StructField(\"quantity\", DoubleType()),\n        StructField(\"sequence\", IntegerType()),\n        StructField(\"unitPrice\", schema_value_currency),\n        StructField(\"externalId\", StringType()),\n        StructField(\"totalValue\", schema_value_currency),\n        StructField(\"customerNote\", StringType()),\n        StructField(\"garnishItems\", ArrayType(schema_garnish)),\n        StructField(\"integrationId\", StringType()),\n        StructField(\"totalAddition\", schema_value_currency),\n        StructField(\"totalDiscount\", schema_value_currency)\n    ])\n\n# Definação do schema json\nschema_json = StructType(\n    [\n        StructField(\"cpf\", StringType()),\n        StructField(\"customer_id\", StringType()),\n        StructField(\"customer_name\", StringType()),\n        StructField(\"delivery_address_city\", StringType()),\n        StructField(\"delivery_address_country\", StringType()),\n        StructField(\"delivery_address_district\", StringType()),\n        StructField(\"delivery_address_external_id\", StringType()),\n        StructField(\"delivery_address_latitude\", StringType()),\n        StructField(\"delivery_address_longitude\", StringType()),\n        StructField(\"delivery_address_state\", StringType()),\n        StructField(\"delivery_address_zip_code\", StringType()),\n        StructField(\"items\", StringType()),\n        StructField(\"merchant_id\", StringType()),\n        StructField(\"merchant_latitude\", StringType()),\n        StructField(\"merchant_longitude\", StringType()),\n        StructField(\"merchant_timezone\", StringType()),\n        StructField(\"order_created_at\", StringType()),\n        StructField(\"order_id\", StringType()),\n        StructField(\"order_scheduled\", BooleanType()),\n        StructField(\"order_scheduled_date\", StringType()),\n        StructField(\"order_total_amount\", DoubleType()),\n        StructField(\"origin_platform\", StringType())\n    ])\n    \n# Referência de processamento\nref = str(datetime.today() - timedelta(days=1))[0:10]\n\n# Caminho de origem da pouso order\norigem_pouso = \"hdfs://localhost:9000/ifood-landing-order/dt={}/*.json\".format(ref)\n\n# Caminho de destino do incremental\ndestino_incremental = \"hdfs://localhost:9000/ifood-raw-order/\"\n\n# Inicia sessão spark\nspark = SparkSession.builder.appName(\"ifood-raw-order-prod\").getOrCreate()\n\n# Configurações básicas para o spark\nspark.conf.set(\"spark.sql.maxPartitionBytes\", 200 * 1024 * 1024) # Seta a quantidade máxima de bytes em uma partição ao ler os arquivos de entrada (Entre 100MB e 200MB é o ideal)\nspark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"DYNAMIC\") # Necessário para sobrescrever partições ","user":"anonymous","dateUpdated":"2019-12-25T01:58:10-0300","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1577225266286_27910111","id":"20191221-124444_835401478","dateCreated":"2019-12-24T19:07:46-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:27"},{"title":"Lê os dados da origem","text":"%pyspark\n\n# Lê a pouso de origem\npousoDF = spark.read.schema(schema_json).json(origem_pouso)","user":"anonymous","dateUpdated":"2019-12-25T01:58:53-0300","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1577225266330_-1689940368","id":"20191221-124622_2019804708","dateCreated":"2019-12-24T19:07:46-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:28"},{"text":"%pyspark\n\npousoDF_ = pousoDF \\\n    .withColumn(\"items\", from_json(\"items\", ArrayType(schema_items)))","user":"anonymous","dateUpdated":"2019-12-25T01:59:19-0300","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1577249933582_280141254","id":"20191225-015853_2001336009","dateCreated":"2019-12-25T01:58:53-0300","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:196","title":"Altera o schema da coluna items para ser reconhecida como um array"},{"title":"Cria e grava a tabela raw","text":"%pyspark\n\n# Cria a tabela raw\nrawDF = pousoDF_ \\\n    .withColumn(\"dt_proc\", current_date()) \\\n    .withColumn(\"dt\", col(\"order_created_at\").cast(DateType())) \\\n    .repartition(100, \"dt\")\n\nrawDF.write.partitionBy(\"dt\").mode(\"overwrite\").option(\"compression\", \"snappy\").format(\"parquet\").save(destino_raw)","user":"anonymous","dateUpdated":"2019-12-25T01:59:38-0300","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1577225266342_-2110338669","id":"20191221-124855_1400670421","dateCreated":"2019-12-24T19:07:46-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:29"},{"title":"Validação","text":"%pyspark\n\n# Leitura da base final\nrawDF_ = spark.read.parquet(destino_raw).filter(col(\"dt\") == lit(ref))\n\n# Validação Volumétrica\nprint(\"> Volumetria de saída equivale-se a de entrada ? --> {}\".format(pousoDF.count() == rawDF_.count()))\n\n# Validação do Schema\nschema = pousoDF.schema\nschema_ = rawDF_.drop(\"dt\", \"dt_proc\").schema\ncolunas = pousoDF.columns\ncolunas_ = rawDF_.drop(\"dt\", \"dt_proc\").columns\ncolunas.sort()\ncolunas_.sort()\nprint(\"> O schema de saída equivale-se ao de entrada ? ---> {}\".format(schema == schema_ or colunas == colunas_))","user":"anonymous","dateUpdated":"2019-12-24T19:07:46-0300","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"> Volumetria de saída equivale-se a de entrada ? --> True\n> O schema de saída equivale-se ao de entrada ? ---> True\n"}]},"apps":[],"jobName":"paragraph_1577225266343_956580631","id":"20191221-125122_890996710","dateCreated":"2019-12-24T19:07:46-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:30"}],"name":"ifood-raw-order-prod","id":"2EUYKJN4G","noteParams":{},"noteForms":{},"angularObjects":{"python:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}